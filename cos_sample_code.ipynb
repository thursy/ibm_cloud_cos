{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Files to Cloud Object Storage\n",
    "\n",
    "This notebook will try to upload from your local into Cloud Object Storage in IBM Cloud Bucket\n",
    "Things to prepare:\n",
    "- APIKEY info\n",
    "- INSTANCE CRN info\n",
    "- Public endpoint info\n",
    "\n",
    "\n",
    "How to create service credential? Please see [this reference](https://cloud.ibm.com/docs/cloud-object-storage/iam?topic=cloud-object-storage-service-credentials).\n",
    "\n",
    "Reference that could help:\n",
    "- [IBM COS Reference python](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-python)\n",
    "- [IBM COS Python SKD Documentation](https://ibm.github.io/ibm-cos-sdk-python/reference/services/index.html)\n",
    "- [IBM COS endpoint](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-endpoints#endpoints)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install COS python SDK\n",
    "\n",
    "if you not yet install SDK, please run this code, otherwise you can skip this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U ibm-cos-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dependencies and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import ibm_boto3\n",
    "from ibm_botocore.client import Config, ClientError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get endpoint url, open your bucket configuration, under the _Endpoint section_ you can find the information about the URL.\n",
    "From the configuration you also can find the information about location and object class.\n",
    "Current list avaiable at https://control.cloud-object-storage.cloud.ibm.com/v2/endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_url_private = \"s3.private.us-east.cloud-object-storage.appdomain.cloud\"\n",
    "endpoint_url_public = \"s3.us-east.cloud-object-storage.appdomain.cloud\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COS_ENDPOINT = \"https://\"+endpoint_url_public \n",
    "COS_API_KEY_ID =  #eg: \"W00YixxxxxxxxxxMB-xxx-2ySxxxxxxxxxxxxc--Pxxxk\"\n",
    "COS_INSTANCE_CRN = #eg: \"crn:v1:bluemix:public:cloud-object-storage:global:a/3bfxxxxxxxxxxxxxxxxxxxxxxxxxxx1c:dxxxxxx3-6xxf-4xx2-axx5-6xxxxxxxxx3::\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on SDK Documentation the connection can be established by using _Client_ or _Resources_\n",
    "\n",
    "## Client\n",
    "\n",
    "This part executing functions that can be accesed using Client.\n",
    "This is just a example to get the bucket name and list the objects, but it capped to 1000 files only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = ibm_boto3.client(\"s3\",\n",
    "    ibm_api_key_id=COS_API_KEY_ID,\n",
    "    ibm_service_instance_id=COS_INSTANCE_CRN,\n",
    "    config=Config(signature_version=\"oauth\"),\n",
    "    endpoint_url=COS_ENDPOINT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = cos.list_buckets()['Buckets'][0]['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = cos.list_objects(Bucket=bucket_name,)\n",
    "len([name['Key'] for name in response['Contents']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "This part executing functions that can be accesed using Resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ibm_boto3.resource(\"s3\",\n",
    "    ibm_api_key_id=COS_API_KEY_ID,\n",
    "    ibm_service_instance_id=COS_INSTANCE_CRN,\n",
    "    config=Config(signature_version=\"oauth\"),\n",
    "    endpoint_url=COS_ENDPOINT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the available bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_buckets():\n",
    "    print(\"Retrieving list of buckets\")\n",
    "    bucket_list = []\n",
    "    try:\n",
    "        buckets = res.buckets.all()\n",
    "        for bucket in buckets:\n",
    "            print(\"Bucket Name: {0}\".format(bucket.name))\n",
    "            bucket_list.append(bucket.name)\n",
    "        return bucket_list\n",
    "    except ClientError as be:\n",
    "        print(\"CLIENT ERROR: {0}\\n\".format(be))\n",
    "    except Exception as e:\n",
    "        print(\"Unable to retrieve list buckets: {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_bucket = get_buckets()\n",
    "avail_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = avail_bucket[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the available objects inside bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bucket_contents(bucket_name):\n",
    "    print(\"Retrieving bucket contents from: {0}\".format(bucket_name))\n",
    "    obj_list = []\n",
    "    try:\n",
    "        files = res.Bucket(bucket_name).objects.all()\n",
    "        for file in files:\n",
    "            file_info = {}\n",
    "            #print(\"Item: {0} ({1} bytes).\".format(file.key, file.size))\n",
    "            file_info['filename'] = file.key\n",
    "            file_info['filesize'] = file.size\n",
    "            obj_list.append(file_info)\n",
    "        return obj_list\n",
    "    except ClientError as be:\n",
    "        print(\"CLIENT ERROR: {0}\\n\".format(be))\n",
    "    except Exception as e:\n",
    "        print(\"Unable to retrieve bucket contents: {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_obj = get_bucket_contents(bucket_name)\n",
    "avail_obj_df = pd.DataFrame(avail_obj)\n",
    "avail_obj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_obj_df.filesize.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all files inside the uncompressed folder\n",
    "\n",
    "__CAUTION: Ensure the uncompressed folder you about to upload is in the same level (folder) with your cos_sample_code.ipynb file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_folder_path = 'your_local_uncompressed_folder_path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obj_list(folder_path, obj_list = []):\n",
    "    with os.scandir(folder_path) as entries:\n",
    "        for entry in entries:\n",
    "            if entry.name!= '.DS_Store':\n",
    "                file_path = os.path.join(folder_path,entry.name)\n",
    "                if entry.is_dir():\n",
    "                    get_obj_list(file_path, obj_list)\n",
    "                if entry.is_file():\n",
    "                    obj_list.append(file_path)\n",
    "        return obj_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_file_list = get_obj_list(local_folder_path,[])\n",
    "len(local_file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##uncomment to test with sample files first, after upload going ok, then delete the file\n",
    "#res.Bucket(bucket_name).upload_file('sample.txt', 'check/sample.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this if you try to upload file you need to provide a path\n",
    "def upload_file(bucket_name, item_name):\n",
    "    print(\"Starting upload item to bucket: {0}, key: {1}\".format(bucket_name, item_name))\n",
    "    try:\n",
    "        res.Bucket(bucket_name).upload_file(item_name, item_name)\n",
    "        print(\"uploaded file: \", item_name)\n",
    "        return item_name\n",
    "    except Exception as e:\n",
    "        print(\"Unable to retrieve file contents: {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this if you try to upload an object (opened file) or binary file\n",
    "def upload_file_obj(bucket_name, item_name):\n",
    "    print(\"Starting upload item to bucket: {0}, key: {1}\".format(bucket_name, item_name))\n",
    "    with open('filename.png', 'rb') as item_bin:\n",
    "        try:\n",
    "            #uncomment this in case you need to upload binary object, wrap it using Bytesio first\n",
    "            #from io import BytesIO\n",
    "            #res.Bucket(bucket_name).Object(item_name).upload_fileobj(BytesIO(item_bin))\n",
    "            res.Bucket(bucket_name).Object(item_name).upload_fileobj(item_bin)\n",
    "            print(\"uploaded file: \", item_name)\n",
    "            return f\"{COS_ENDPOINT}/{bucket_name}/{item_name}\"\n",
    "        except Exception as e:\n",
    "            print(\"Unable to retrieve file contents: {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_file_list = []\n",
    "\n",
    "for file_path in local_file_list:\n",
    "    upload_file(bucket_name, file_path)\n",
    "    uploaded_file_list.append(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_obj = get_bucket_contents(bucket_name)\n",
    "avail_obj_df = pd.DataFrame(avail_obj)\n",
    "avail_obj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unuploaded = [file_path for file_path in local_file_list if file_path not in list(avail_obj_df['filename'].unique())]\n",
    "unuploaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(bucket_name, filename, filename_local):\n",
    "    res.Object(bucket_name, filename).download_file(filename_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file_obj(bucket_name, item_name):\n",
    "    obj = res.Bucket(bucket_name).Object(item_name)\n",
    "    \n",
    "    #print(type(obj))\n",
    "    with open('filename.png', 'wb') as data:\n",
    "        obj.download_fileobj(data)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
